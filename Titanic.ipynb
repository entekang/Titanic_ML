{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is my solution in predicting survival with Titanic dataset. \n\nIt is also my very first time programming in Python and doing a data science project. \n\nAny thoughts, suggestions and comments are greatly appreciated. \n\nThe first submission yielded an accuracy of 0.78468."},{"metadata":{},"cell_type":"markdown","source":"**Question of interest**\n\n*Use a Machine Learning model to predict which passengers survived the shipwreck given various features of the passengers.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/titanic/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata = train_data.copy()\ntesdata = test_data.copy()\ndsets = [trdata,tesdata]\nprint(trdata.head())\nprint(trdata.info())\nprint(tesdata.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's assess the relationship between the features and our question of interest.\n- A few things to note: \n    - it may make more sense to analyze age and fare in groups \n    - I expect the passenger id and ticket columns to not have an association with survival "},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata.groupby('Sex').Survived.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- A much higher proportion of females survived the incident"},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata.groupby('Pclass')['Survived'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Passengers of higher socio economic status were more likely to survive "},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata.groupby('Embarked')['Survived'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Survived', data=trdata, hue='Embarked')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- A higher proportion of passengers who embarked at Cherbourg survived in comparson to other ports of embarkation. \n- Most passengers embarked at Southampton, which also leads to the most deaths when comparing by where the passengers embarked\n- embarked will be included as a feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.groupby('SibSp')['Survived'].mean())\nprint(trdata.groupby('Parch').Survived.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The features SibSp and Parch do not seem to be that useful in predicting survival.\n- Perhaps creating a 'Family' feature indicating the size of the family on board could be useful \n- Based on the family feature, an 'Alone' feature can be created indicating whether the passenger was travelling alone "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='Survived', hue='Sex', data=trdata, kind='count', col='Pclass')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* In all Pclasses, females were more likely than males to survive. Justifying the inclusion of Sex and Pclass as features into our model "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='Survived', y='Fare', data=train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g=sns.FacetGrid(trdata, col='Survived')\ng.map(plt.hist, 'Age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The conclusion from the above graphs are that bins should be created for age and fare"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill in the missing values in age and fare with the median value. \n# the median is used as there are a few outliers for these features.\n# there is an 80 year old on board, along with a passenger who paid $512.\n\nage_med=trdata['Age'].median()\nfare_med=trdata['Fare'].median()\ntesdata['Fare'].fillna(fare_med, inplace=True)\n\n# impute median\nfor dset in dsets:\n    dset['Age'].fillna(age_med, inplace=True)\n    \n# create bins for age\nage_bins = [-np.inf, 20, 40, 60, np.inf]\nfare_bins = [-np.inf, 128.082, 256.165, 384.247, np.inf]\nlabs = [0, 1, 2, 3]\n\n\n\nfor dset in dsets:\n    dset['Agebin'] = pd.cut(dset['Age'], bins=age_bins, labels=labs)\n    dset['Farebin'] = pd.cut(dset['Fare'], bins=fare_bins, labels=labs)\n    dset['Agebin'].astype('int64')\n    dset['Farebin'].astype('int64')\n    \n    \nprint(trdata['Agebin'].unique())\nprint(trdata['Farebin'].unique())\n\n# sns.countplot(x='Survived', data=trdata, hue='Agebin')\n# plt.figure()\n# sns.countplot(x='Survived', data=trdata, hue='Farebin')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata.groupby('Agebin')['Survived'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata.groupby('Farebin')['Survived'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata.groupby('Farebin')['Survived'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Young passengers were more likely to survive \n* The 3 highest paying passengers survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a family feature\n\nfor dset in dsets:\n    dset['Family'] = dset['SibSp'] + dset['Parch'] + 1\n\ntrdata.groupby('Family')['Survived'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* In general, large families were less likely to survive, it would be very cold-hearted to leave family members behind"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create an 'Alone' feature \n# Alone = 1 if the passenger is onboard by him/herself\nfor dset in dsets:\n    dset['Alone']=1\n    dset.loc[dset['Family'] > 1, 'Alone'] = 0\n    \ntrdata.groupby('Alone')['Survived'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Passengers that were not alone on average were more likely to survive."},{"metadata":{},"cell_type":"markdown","source":"**Drop the family feature to prevent colinearity**.  "},{"metadata":{},"cell_type":"markdown","source":"Fill in the missing values for Embarked with the most frequent"},{"metadata":{"trusted":true},"cell_type":"code","source":"mode_emb = trdata['Embarked'].mode()[0]\ntrdata['Embarked'].fillna(mode_emb, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Drop PassengerId, Name, Age, SibSp, Parch, Ticket, Fare, Cabin, Family\n* Dummy code Sex, Embarked"},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_dummy_tr = pd.get_dummies(trdata['Embarked'], drop_first=True)\nsex_dummy_tr = pd.get_dummies(trdata['Sex'], drop_first=True)\nemb_dummy_te = pd.get_dummies(tesdata['Embarked'], drop_first=True)\nsex_dummy_te = pd.get_dummies(tesdata['Sex'], drop_first=True)\n\ntrdata_enc = pd.concat([trdata, emb_dummy_tr, sex_dummy_tr], axis=1)\ntesdata_enc = pd.concat([tesdata, emb_dummy_te, sex_dummy_te], axis=1)\n\ntrdata_enc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_col = ['PassengerId', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Family']\ndset_enc = [trdata_enc, tesdata_enc]\nfor dset in dset_enc:\n    dset.drop(drop_col, axis=1, inplace=True)\n    \ntrdata_enc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tesdata_enc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = trdata_enc.Survived\nX_train = trdata_enc.drop('Survived', axis=1)\nX_test = tesdata_enc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will fit and make predictions with our models. \n* K Neighbours\n* Logistic Regression\n* Decision Trees\n* Random Forest\n* Voting classifier\n* Gradient boosting "},{"metadata":{"trusted":true},"cell_type":"code","source":"rs = 99\nlr = LogisticRegression(random_state=rs)\nknn = KNN()\ndt=DecisionTreeClassifier(random_state=rs)\nclassifiers = [('Logistic Regression', lr), ('K Nearest Neighbors', knn), ('Decision Tree', dt)]\n\nfor clfname, clf in classifiers:\n    # fit the model\n    clf.fit(X_train, y_train)\n    \n    # predict\n    pred = clf.predict(X_test)\n    \n    # score of the model \n    print('The score of {} is {:.4f}'.format(clfname, clf.score(X_train, y_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc=VotingClassifier(estimators=classifiers)\nvc.fit(X_train, y_train)\nvc_pred = vc.predict(X_test)\nprint('The score of the Voting classifier is: {:.4f}'.format(vc.score(X_train, y_train)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf=RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nprint('The score of the Random Forest classifier is: {:.4f}'.format(rf.score(X_train, y_train)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb=GradientBoostingClassifier()\ngb.fit(X_train, y_train)\ngb_pred = gb.predict(X_test)\nprint('The score of the Gradient Boosting classifier is: {:.4f}'.format(gb.score(X_train, y_train)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Choose the Random Forest Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': tesdata.PassengerId, 'Survived': rf_pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}